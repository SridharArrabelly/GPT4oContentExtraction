{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b627d38b-d9dc-4106-8c87-c15ebe918812",
   "metadata": {},
   "source": [
    "# Important\n",
    "- Edit config.json and add your service details\n",
    "- Edit the base_url in this notebook to point to your Azure Container App service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c94cda-b58d-4441-b777-fb57a7914caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob  \n",
    "import requests  \n",
    "import time\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient  \n",
    "import concurrent.futures  \n",
    "from functools import partial  \n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfafb99-d471-45df-b234-0fcc68359bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the service configurations and set the file to process\n",
    "with open(\"config.json\", \"r\") as c_in:\n",
    "    data = json.loads(c_in.read())\n",
    "data['url_file_to_process'] = 'https://github.com/liamca/GPT4oContentExtraction/raw/main/Transforming-Content-with-GPT4o.pptx'\n",
    "\n",
    "# base_url = \"http://127.0.0.1:3100\"\n",
    "base_url = \"https://[container service.[region].azurecontainerapps.io\"\n",
    "\n",
    "job_submit_url = f\"{base_url}/start-job\"\n",
    "job_status_url = f\"{base_url}/job-status\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399c6477-1cea-411e-a2fe-2248680d657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job started successfully! Job ID: 695f1b55-222e-4da5-9aec-616f374b60b7\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Checking if file needs to be converted to PDF...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 695f1b55-222e-4da5-9aec-616f374b60b7: complete\n",
      "Processing complete.\n",
      "{'job_id': '695f1b55-222e-4da5-9aec-616f374b60b7', 'status': 'complete', 'message': 'Processing complete.'}\n"
     ]
    }
   ],
   "source": [
    "# Submit job to convert the document to Markdown files\n",
    "response = requests.post(job_submit_url, json=data)  \n",
    "\n",
    "# Check if the request was successful  \n",
    "if response.status_code == 200:  \n",
    "    job_info = response.json()  \n",
    "    job_id=job_info['job_id']\n",
    "    print(f\"Job started successfully! Job ID: {job_id}\")  \n",
    "    data_status = { \n",
    "        \"job_id\": job_info['job_id'],\n",
    "        \"blob_storage_service_name\" : data['blob_storage_service_name'],\n",
    "        \"blob_storage_service_api_key\" : data['blob_storage_service_api_key'],\n",
    "        \"blob_storage_container\" : data['blob_storage_container']\n",
    "    }  \n",
    "    \n",
    "    # Send requests to check job status  \n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        response = requests.post(job_status_url, json=data_status)  \n",
    "\n",
    "        # Check if the request was successful  \n",
    "        if response.status_code == 200:  \n",
    "            job_status = response.json()  \n",
    "            print(f\"Job Status for Job ID {job_id}: {job_status['status']}\")  \n",
    "            if 'message' in job_status:\n",
    "                print(f\"{job_status['message']}\")  \n",
    "            if job_status['status'] != 'in-progress':\n",
    "                print (job_status)\n",
    "                break\n",
    "        else:  \n",
    "            print(f\"Failed to check job status: {response.status_code} - {response.text}\")  \n",
    "            break\n",
    "else:  \n",
    "    print(f\"Failed to start job: {response.status_code} - {response.text}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3573de-2235-49e9-a755-9467e6ba452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/1.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/1.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/2.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/2.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/3.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/3.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/4.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/4.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/5.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/5.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/6.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/6.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/7.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/7.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/8.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/8.png\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/images\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/images/9.png to 695f1b55-222e-4da5-9aec-616f374b60b7/images/9.png\n",
      "Directory created: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/1.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/1.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/2.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/2.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/3.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/3.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/4.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/4.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/5.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/5.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/6.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/6.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/7.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/7.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/8.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/8.txt\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7/markdown\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/9.txt to 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/9.txt\n",
      "Directory created: 695f1b55-222e-4da5-9aec-616f374b60b7/pdf\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/pdf/Transforming-Content-with-GPT4o.pdf to 695f1b55-222e-4da5-9aec-616f374b60b7/pdf/Transforming-Content-with-GPT4o.pdf\n",
      "Directory already exists: 695f1b55-222e-4da5-9aec-616f374b60b7\n",
      "Downloaded 695f1b55-222e-4da5-9aec-616f374b60b7/status.json to 695f1b55-222e-4da5-9aec-616f374b60b7/status.json\n",
      "Download completed!\n"
     ]
    }
   ],
   "source": [
    "# Download the files that were processed\n",
    "connection_string = f\"DefaultEndpointsProtocol=https;AccountName={data['blob_storage_service_name']};AccountKey={data['blob_storage_service_api_key']};EndpointSuffix=core.windows.net\"  \n",
    "container_name = data['blob_storage_container']\n",
    "folder_name = job_info['job_id']\n",
    "\n",
    "# Initialize the BlobServiceClient and ContainerClient  \n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)  \n",
    "container_client = blob_service_client.get_container_client(container_name)  \n",
    "blobs = container_client.list_blobs(name_starts_with=folder_name)  \n",
    "\n",
    "# Define the local directory to save the downloaded files  \n",
    "local_path = job_info['job_id']  \n",
    "\n",
    "# Ensure the local directory exists  \n",
    "if not os.path.exists(local_path):  \n",
    "    os.makedirs(local_path)  \n",
    "\n",
    "# Download each blob  \n",
    "for blob in blobs:  \n",
    "    blob_client = container_client.get_blob_client(blob)  \n",
    "    blob_name = blob.name  \n",
    "    # Create the full local path  \n",
    "    local_file_path = blob_name\n",
    "    utils.ensure_directory_exists(os.path.dirname(local_file_path))\n",
    "\n",
    "    # Download the blob to the local file  \n",
    "    with open(local_file_path, \"wb\") as download_file:  \n",
    "        download_file.write(blob_client.download_blob().readall())  \n",
    "\n",
    "    print(f\"Downloaded {blob_name} to {local_file_path}\")  \n",
    "\n",
    "print(\"Download completed!\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc826ef-8e6d-49ca-8c1b-05579960bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions in Embedding Model: 1536\n",
      "Index test deleted successfully.\n",
      "Index test created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Re-create the index\n",
    "utils.create_index(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ebcb45-aaab-4f20-9a48-d755ab9c01ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing content...\n",
      "Directory created: 695f1b55-222e-4da5-9aec-616f374b60b7/json\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/1.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/2.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/3.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/4.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/5.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/6.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/7.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/8.txt\n",
      "file 695f1b55-222e-4da5-9aec-616f374b60b7/markdown/9.txt\n",
      "['695f1b55-222e-4da5-9aec-616f374b60b7/markdown/1.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/2.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/3.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/4.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/5.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/6.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/7.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/8.txt', '695f1b55-222e-4da5-9aec-616f374b60b7/markdown/9.txt']\n",
      "Total JSON Files: 9\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the content and store in an AI Search compatible JSON format\n",
    "max_workers = 15\n",
    "\n",
    "print ('Vectorizing content...')\n",
    "markdown_files = glob.glob(os.path.join(os.path.join(folder_name, 'markdown'), \"*.txt\"))  \n",
    "json_out_dir = os.path.join(job_info['job_id'], 'json')\n",
    "utils.ensure_directory_exists(json_out_dir)\n",
    "\n",
    "partial_process_json = partial(utils.process_json, doc_id=job_info['job_id'], json_out_dir=json_out_dir, data=data)  \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:  \n",
    "    results = list(executor.map(partial_process_json, markdown_files))  \n",
    "print(results)  \n",
    "\n",
    "json_files = glob.glob(os.path.join(json_out_dir, \"*.json\"))\n",
    "total_files = len(json_files)\n",
    "print ('Total JSON Files:', total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6677b52-6fc0-4371-a25f-a6722897aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing content...\n",
      "Documents Indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Index content\n",
    "print ('Indexing content...')\n",
    "utils.index_content(json_files, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75e7c6-13bc-42ff-acad-32358facbc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_default",
   "language": "python",
   "name": "py39_default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
