{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa378800-67b0-49a0-8754-2ecb6c872900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob  \n",
    "import requests  \n",
    "import time\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient  \n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path  \n",
    "import concurrent.futures  \n",
    "from functools import partial  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfafb99-d471-45df-b234-0fcc68359bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to send in the job request (optional)  \n",
    "data = {  \n",
    "    \"openai_gpt_api_base\" : \"https://[].openai.azure.com/\",\n",
    "    \"openai_gpt_api_key\" : \"[]\",\n",
    "    \"openai_gpt_api_version\" :  \"2024-02-15-preview\",\n",
    "    \"openai_gpt_model\" : \"gpt-4o\",\n",
    "    \"blob_storage_service_name\" : \"[]\",\n",
    "    \"blob_storage_service_api_key\" : \"[]\",\n",
    "    \"blob_storage_container\" : \"insight-engine-data\",\n",
    "    \"openai_embedding_api_base\" : \"https://[].openai.azure.com/\",\n",
    "    \"openai_embedding_api_key\" : \"[]\",\n",
    "    \"openai_embedding_api_version\" :  \"2024-02-15-preview\",\n",
    "    \"openai_embedding_model\" : \"text-embedding-ada-002\",\n",
    "    \"search_service_name\": \"[]\",\n",
    "    \"search_admin_key\" : \"[]\",\n",
    "    \"search_index_name\": \"test\",\n",
    "    \"search_api_version\" : \"2024-05-01-preview\",\n",
    "}  \n",
    "\n",
    "data['url_file_to_process'] = 'https://github.com/liamca/GPT4oContentExtraction/raw/main/Transforming-Content-with-GPT4o.pptx'\n",
    "# base_url = \"http://127.0.0.1:3100\"\n",
    "base_url = \"https://liamca-aca-doc2md.salmonpebble-e154b31c.westus2.azurecontainerapps.io\"\n",
    "\n",
    "job_submit_url = f\"{base_url}/start-job\"\n",
    "job_status_url = f\"{base_url}/job-status\"\n",
    "\n",
    "search_headers = {  \n",
    "    'Content-Type': 'application/json',  \n",
    "    'api-key': data['search_admin_key']\n",
    "}  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb18798a-67f9-4b09-9402-9ac19f18280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate vectors for title and content fields, also used for query vectors\n",
    "max_attempts = 6\n",
    "max_backoff = 60\n",
    "def generate_embedding(text):\n",
    "    if text == None:\n",
    "        return None\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        api_version=data['openai_embedding_api_version'],\n",
    "        azure_endpoint=data['openai_embedding_api_base'],\n",
    "        api_key=data['openai_embedding_api_key']\n",
    "    )    \n",
    "    counter = 0\n",
    "    incremental_backoff = 1   # seconds to wait on throttline - this will be incremental backoff\n",
    "    while True and counter < max_attempts:\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                input=text,\n",
    "                model=data['openai_embedding_model']\n",
    "            )\n",
    "            return json.loads(response.model_dump_json())[\"data\"][0]['embedding']\n",
    "        except openai.APIError as ex:\n",
    "            # Handlethrottling - code 429\n",
    "            if str(ex.code) == \"429\":\n",
    "                incremental_backoff = min(max_backoff, incremental_backoff * 1.5)\n",
    "                print ('Waiting to retry after', incremental_backoff, 'seconds...')\n",
    "                time.sleep(incremental_backoff)\n",
    "            elif str(ex.code) == \"content_filter\":\n",
    "                print ('API Error', ex.code)\n",
    "                return None\n",
    "        except Exception as ex:\n",
    "            counter += 1\n",
    "            print ('Error - Retry count:', counter, ex)\n",
    "    return None\n",
    "    \n",
    "def create_index():\n",
    "    dims = len(generate_embedding('The quick brown fox.'))\n",
    "    print ('Dimensions in Embedding Model:', dims)\n",
    "    \n",
    "    with open(\"schema.json\", \"r\") as f_in:\n",
    "        index_schema = json.loads(f_in.read())\n",
    "        index_schema['name'] = data['search_index_name']\n",
    "        index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['resourceUri'] = data['openai_embedding_api_base']\n",
    "        index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['deploymentId'] = data['openai_embedding_model']\n",
    "        index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['apiKey'] = data['openai_embedding_api_key']\n",
    "\n",
    "    # Making the POST requests to re-create the index  \n",
    "    search_service_url = \"https://{}.search.windows.net/\".format(data['search_service_name'])\n",
    "    delete_url = f\"{search_service_url}/indexes/{data['search_index_name']}?api-version={data['search_api_version']}\"  \n",
    "    response = requests.delete(delete_url, headers=search_headers)  \n",
    "    if response.status_code == 204:  \n",
    "        print(f\"Index {data['search_index_name']} deleted successfully.\")  \n",
    "        # print(json.dumps(response.json(), indent=2))  \n",
    "    else:  \n",
    "        print(\"Error deleting index, it may not exist.\")  \n",
    "    \n",
    "    # The endpoint URL for creating the index  \n",
    "    create_index_url = f\"{search_service_url}/indexes?api-version={data['search_api_version']}\"  \n",
    "    response = requests.post(create_index_url, headers=search_headers, json=index_schema)  \n",
    "      \n",
    "    # Check the response  \n",
    "    if response.status_code == 201:  \n",
    "        print(f\"Index {data['search_index_name']} created successfully.\")  \n",
    "        # print(json.dumps(response.json(), indent=2))  \n",
    "    else:  \n",
    "        print(f\"Error creating index {data['search_index_name']} :\")  \n",
    "        print(response.json())\n",
    "\n",
    "# Create directory if it does not exist\n",
    "def ensure_directory_exists(directory_path):  \n",
    "    path = Path(directory_path)  \n",
    "    if not path.exists():  \n",
    "        path.mkdir(parents=True, exist_ok=True)  \n",
    "        print(f\"Directory created: {directory_path}\")  \n",
    "    else:  \n",
    "        print(f\"Directory already exists: {directory_path}\")  \n",
    "\n",
    "def process_json(file, doc_id, json_out_dir):\n",
    "    print ('file', file)\n",
    "    if '.txt' in file:\n",
    "        with open(file, 'r', encoding=\"utf8\") as c_in:\n",
    "            content = c_in.read()\n",
    "\n",
    "        json_data = {\n",
    "            'doc_id': doc_id, \n",
    "            'page_number': int(os.path.basename(file).replace('.txt', '')),\n",
    "            'content': content\n",
    "            }\n",
    "\n",
    "        json_data['vector'] = generate_embedding(json_data['content'])\n",
    "\n",
    "\n",
    "        with open(os.path.join(json_out_dir, os.path.basename(file).replace('.txt', '.json')), 'w') as c_out:\n",
    "            c_out.write(json.dumps(json_data, indent=4))\n",
    "\n",
    "    else:\n",
    "        print ('Skipping non JSON file:', file)\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "def index_content(json_files):\n",
    "    # Index the content\n",
    "    batch_size = 50\n",
    "    search_service_url = \"https://{}.search.windows.net/\".format(data['search_service_name'])\n",
    "    index_doc_url = f\"{search_service_url}/indexes/{data['search_index_name']}/docs/index?api-version={data['search_api_version']}\" \n",
    "    \n",
    "    documents = {\"value\": []}\n",
    "    for file in json_files:\n",
    "        if '.json' in file:\n",
    "            with open(file, 'r') as j_in:\n",
    "                json_data = json.loads(j_in.read())\n",
    "            json_data['doc_id'] = json_data['doc_id'] + '-' + str(json_data['page_number'])\n",
    "            documents[\"value\"].append(json_data)\n",
    "            if len(documents[\"value\"]) == batch_size:\n",
    "                response = requests.post(index_doc_url, headers=search_headers, json=documents)  \n",
    "                # Check the response  \n",
    "                if response.status_code == 200:  \n",
    "                    print(f\"Document Indexed successfully.\")  \n",
    "                    # print(json.dumps(response.json(), indent=2))  \n",
    "                else:  \n",
    "                    print(f\"Error indexing document {file} :\")  \n",
    "                    print(response.json())  \n",
    "                documents = {\"value\": []}\n",
    "                \n",
    "    response = requests.post(index_doc_url, headers=search_headers, json=documents)  \n",
    "    # Check the response  \n",
    "    if response.status_code == 200:  \n",
    "        print(f\"Documents Indexed successfully.\")  \n",
    "        # print(json.dumps(response.json(), indent=2))  \n",
    "    else:  \n",
    "        print(f\"Error indexing documents {file} :\")  \n",
    "        print(response.json())  \n",
    "    documents = {\"value\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399c6477-1cea-411e-a2fe-2248680d657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job started successfully! Job ID: 4ff0e714-ed34-40e8-ab07-12a212c78b92\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: in-progress\n",
      "Converting images to Markdown...\n",
      "Job Status for Job ID 4ff0e714-ed34-40e8-ab07-12a212c78b92: complete\n",
      "Processing complete.\n",
      "{'job_id': '4ff0e714-ed34-40e8-ab07-12a212c78b92', 'status': 'complete', 'message': 'Processing complete.'}\n"
     ]
    }
   ],
   "source": [
    "# Submit job to convert the document to Markdown files\n",
    "response = requests.post(job_submit_url, json=data)  \n",
    "\n",
    "# Check if the request was successful  \n",
    "if response.status_code == 200:  \n",
    "    job_info = response.json()  \n",
    "    job_id=job_info['job_id']\n",
    "    print(f\"Job started successfully! Job ID: {job_id}\")  \n",
    "    data_status = { \n",
    "        \"job_id\": job_info['job_id'],\n",
    "        \"blob_storage_service_name\" : data['blob_storage_service_name'],\n",
    "        \"blob_storage_service_api_key\" : data['blob_storage_service_api_key'],\n",
    "        \"blob_storage_container\" : data['blob_storage_container']\n",
    "    }  \n",
    "    \n",
    "    # Send requests to check job status  \n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        response = requests.post(job_status_url, json=data_status)  \n",
    "\n",
    "        # Check if the request was successful  \n",
    "        if response.status_code == 200:  \n",
    "            job_status = response.json()  \n",
    "            print(f\"Job Status for Job ID {job_id}: {job_status['status']}\")  \n",
    "            if 'message' in job_status:\n",
    "                print(f\"{job_status['message']}\")  \n",
    "            if job_status['status'] != 'in-progress':\n",
    "                print (job_status)\n",
    "                break\n",
    "        else:  \n",
    "            print(f\"Failed to check job status: {response.status_code} - {response.text}\")  \n",
    "            break\n",
    "else:  \n",
    "    print(f\"Failed to start job: {response.status_code} - {response.text}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3573de-2235-49e9-a755-9467e6ba452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/1.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/1.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/2.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/2.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/3.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/3.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/4.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/4.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/5.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/5.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/6.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/6.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/7.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/7.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/8.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/8.png\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/images\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/9.png to 4ff0e714-ed34-40e8-ab07-12a212c78b92/images/9.png\n",
      "Directory created: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/1.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/1.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/2.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/2.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/3.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/3.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/4.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/4.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/5.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/5.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/6.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/6.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/7.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/7.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/8.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/8.txt\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/9.txt to 4ff0e714-ed34-40e8-ab07-12a212c78b92/markdown/9.txt\n",
      "Directory created: 4ff0e714-ed34-40e8-ab07-12a212c78b92/pdf\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/pdf/Transforming-Content-with-GPT4o.pdf to 4ff0e714-ed34-40e8-ab07-12a212c78b92/pdf/Transforming-Content-with-GPT4o.pdf\n",
      "Directory already exists: 4ff0e714-ed34-40e8-ab07-12a212c78b92\n",
      "Downloaded 4ff0e714-ed34-40e8-ab07-12a212c78b92/status.json to 4ff0e714-ed34-40e8-ab07-12a212c78b92/status.json\n",
      "Download completed!\n"
     ]
    }
   ],
   "source": [
    "# Download the files that were processed\n",
    "connection_string = f\"DefaultEndpointsProtocol=https;AccountName={data['blob_storage_service_name']};AccountKey={data['blob_storage_service_api_key']};EndpointSuffix=core.windows.net\"  \n",
    "container_name = data['blob_storage_container']\n",
    "folder_name = job_info['job_id']\n",
    "\n",
    "# Initialize the BlobServiceClient and ContainerClient  \n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)  \n",
    "container_client = blob_service_client.get_container_client(container_name)  \n",
    "blobs = container_client.list_blobs(name_starts_with=folder_name)  \n",
    "\n",
    "# Define the local directory to save the downloaded files  \n",
    "local_path = job_info['job_id']  \n",
    "\n",
    "# Ensure the local directory exists  \n",
    "if not os.path.exists(local_path):  \n",
    "    os.makedirs(local_path)  \n",
    "\n",
    "# Download each blob  \n",
    "for blob in blobs:  \n",
    "    blob_client = container_client.get_blob_client(blob)  \n",
    "    blob_name = blob.name  \n",
    "    # Create the full local path  \n",
    "    local_file_path = blob_name\n",
    "    ensure_directory_exists(os.path.dirname(local_file_path))\n",
    "\n",
    "    # Download the blob to the local file  \n",
    "    with open(local_file_path, \"wb\") as download_file:  \n",
    "        download_file.write(blob_client.download_blob().readall())  \n",
    "\n",
    "    print(f\"Downloaded {blob_name} to {local_file_path}\")  \n",
    "\n",
    "print(\"Download completed!\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc826ef-8e6d-49ca-8c1b-05579960bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions in Embedding Model: 1536\n",
      "Index test deleted successfully.\n",
      "Index test created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Re-create the index\n",
    "create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebcb45-aaab-4f20-9a48-d755ab9c01ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing content...\n",
      "Directory created: 4ff0e714-ed34-40e8-ab07-12a212c78b92\\json\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\1.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\2.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\3.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\4.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\5.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\6.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\7.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\8.txt\n",
      "file 4ff0e714-ed34-40e8-ab07-12a212c78b92\\markdown\\9.txt\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the content and store in an AI Search compatible JSON format\n",
    "max_workers = 15\n",
    "\n",
    "print ('Vectorizing content...')\n",
    "markdown_files = glob.glob(os.path.join(os.path.join(folder_name, 'markdown'), \"*.txt\"))  \n",
    "json_out_dir = os.path.join(job_info['job_id'], 'json')\n",
    "ensure_directory_exists(json_out_dir)\n",
    "\n",
    "partial_process_json = partial(process_json, doc_id=job_info['job_id'], json_out_dir=json_out_dir)  \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:  \n",
    "    results = list(executor.map(partial_process_json, markdown_files))  \n",
    "print(results)  \n",
    "\n",
    "json_files = glob.glob(os.path.join(json_out_dir, \"*.json\"))\n",
    "total_files = len(json_files)\n",
    "print ('Total JSON Files:', total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6677b52-6fc0-4371-a25f-a6722897aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing content...\n",
      "Documents Indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Index content\n",
    "print ('Indexing content...')\n",
    "index_content(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75e7c6-13bc-42ff-acad-32358facbc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_default",
   "language": "python",
   "name": "py39_default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
